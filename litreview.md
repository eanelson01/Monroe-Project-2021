## Literature Review: An overview of the literature and its impact on my research project

### Overview of the Process
The literature review is where I started my project. I knew I had the goal of tracking urbanization, but in the beginning I didn't know how I was going to accomplish it. Did I want to implement some form of population estimation, creating a continous regression problem? Would I rather use building segmentation to count individual buildings, tracking the progress of construction rather than the more particular flow of people? Which would be most feasible given my aims, ability, and resources? The best place to find these answers was the literature and I was able to do so.

### First Steps
With these questions in mind, I started by looking at papers that had to do with that continuous regression problem. It seemed the most closely related to my problem regarding school districts. Upon reading the literature, I began to understand the severe complexity of this question and the lack of answers the community as a whole has on it. After days of searching and coordinating with Professor Frazier, I could only find a handful of articles talking about the process, but these implementations seemed too far-fetched given my ability and resources at the time. For that reason, I figured the question of exact population estimation was one for the future when I have a better grasp on the methods and techniques. I moved onto the building segmentation in order to answer my questions about urbanization in Harrisonburg, VA.

### The Most Impactful Papers
With my renewed focus and narrowed approach, I was able to find more articles outlining an approach. I found around 8 total, with 2 articles providing a clear approach that I felt I could hope to replicate. I outline those two below with a description of their method as well as its impact on my development of my research project. 
1. [U-Net-Id, an Instance Segmentation Model
   for Building Extraction from Satellite
   Images—Case Study in the Joanópolis City, Brazil](https://www.mdpi.com/2072-4292/12/10/1544)
    - This was the first article I read using the U-Net architecture for building segmentation. The authors of the study were able to segment buildings, tracking 3 different masks: building, border, and inner segment. The authors defined the border mask as the border of the building so that there were 4 pixels outside and 3 inside. They defined the inner segment as 2 pixels less than the building segment. The combination of these three masks made clearly defined building segments. This method was best for delineating between closer buildings because of its ability to find these distinct masks. For the training data the authors had to manually segment the 3 masks for each building. This manual process was one major drawback of the method and the main reason for me choosing a different method. The benefit of the paper was its use of a U-Net architecture. Reading the article made me more familiar with the Convolutional Neural Network technique and more aware of the possibilities with the architecture for my own use. Unfortunately, the more complicated approach of 3 different masks was too advanced for me to apply to my own use case. The underlying information and exposure to the UNet architecture was still beneficial in my endeavours, however.
2. [Semantic Segmentation-Based Building Footprint
   Extraction Using Very High-Resolution Satellite
   Images and Multi-Source GIS Data](https://www.mdpi.com/2072-4292/11/4/403)
   - This paper also uses a U-Net Architecture. The authors used the DeepGlobe Satellite Challenge dataset from 2018. This was a challenge dataset created to see who could come up with the best machine learning method for building segmentation. The dataset provides a great opportunity as it has the ground truth images, meaning there is no need for manual classification. Furthermore, the authors of the study did not delineate separate masks, but rather just whether the object was a building or not. To get further training data, the authors applied a series of processes to the images before putting it through the model. This included rotations of the image, changes in colors, changes in gamma, slicing, rescaling, and blurring the image. This made it so that the images were distinct but conveyed the same information, providing more to train on. The main author of the paper, Weijia Li, provided the skeleton [script](https://github.com/liweijia/Satellite-Segmentation) for the U-Net architecture. This makes their method easily replicable, and is one of the main reasons I found their paper so beneficial. The method and datasets provided by this paper laid out the best opportunities moving forward in this project. With further inspection, I was unable to use their method exactly because of its complexity, but I was able to use their information to find additional datasets and scripts that were immensely beneficial in my pursuits.

#### [Information about the Training Dataset](dataset.md)

#### [Home Page](README.md)